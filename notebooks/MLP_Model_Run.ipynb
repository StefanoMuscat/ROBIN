{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511eb6c0",
   "metadata": {},
   "source": [
    "# This Python script can be used to generate predictions for new molecules for the chance of RNA vs Protein binding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a7953",
   "metadata": {},
   "source": [
    "## Software License:\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2022 Yazdani et al. \n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2997b",
   "metadata": {},
   "source": [
    "## Jupyter notebook within the Anaconda platform was used in writing the following script. Python version 3.8.2 was used as the coding language. \n",
    "$\\;\\;\\;\\;\\;\\;$\n",
    "\n",
    "\n",
    "\n",
    "![Python logo](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Python-logo-notext.svg/300px-Python-logo-notext.svg.png)\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328afcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "from platform import python_version\n",
    "print(\"Python version:\")\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e15654",
   "metadata": {},
   "source": [
    "## macOS Catalina version 10.15.7 was used when running this code on the Anaconda platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084c2fc",
   "metadata": {},
   "source": [
    "## This code was written with the following package versions. Please install the following packages with the mentioned versions for consistency of results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ac050",
   "metadata": {},
   "source": [
    "### pandas --> version 1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31eac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pandas version\n",
    "import pandas as pd\n",
    "print(\"pandas version:\")\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9382a1",
   "metadata": {},
   "source": [
    "### numpy --> version 1.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494508f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check numpy version\n",
    "import numpy as np\n",
    "print(\"numpy version:\")\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeab52b",
   "metadata": {},
   "source": [
    "### tensorflow --> version 2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check tensorflow version\n",
    "import tensorflow as tf\n",
    "print(\"tensorflow version:\")\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2725a67",
   "metadata": {},
   "source": [
    "### keras --> version 2.4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check keras version\n",
    "print(\"keras version:\")\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c68056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove warnings\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b06200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages for data processing and running the MLP model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pickle\n",
    "\n",
    "# Gets current directory of the jupyter notebook to use for directories of different files\n",
    "folder_dir = os.getcwd()[:-10]\n",
    "\n",
    "# Load medians of features from the training set to fill in missing values of the new compound set\n",
    "df_medians = pd.read_csv(folder_dir + \"/ML_CSVs/df_all_3_feature_medians.csv\")\n",
    "\n",
    "# Get features assined to medians as a dictionary\n",
    "median_values_dict = dict(zip(df_medians.feature, df_medians.median_value))\n",
    "\n",
    "# Get the features of the training set for use later\n",
    "features = df_medians[\"feature\"].tolist()\n",
    "\n",
    "# Load in the saved Keras model\n",
    "reconstructed_model = keras.models.load_model(folder_dir + \"/MLP_saved_model\")\n",
    "\n",
    "print(\"Processes complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of the new compounds array to be run in the MLP model\n",
    "\n",
    "# Read in Mordred features of the new compound set\n",
    "# As an example, the input here is the 8 compounds shown as test cases in the paper. \n",
    "df_Mordred_extra = pd.read_csv(folder_dir + \"/data/Mordred_files/Mordred_Test_Compounds_3D.csv\")\n",
    "\n",
    "# Take the compound names as a list as they will be used later\n",
    "Mordred_extra_names = df_Mordred_extra[\"name\"].tolist()\n",
    "\n",
    "# Remove the name column\n",
    "df_Mordred_extra_no_name = df_Mordred_extra.iloc[:, 1:]\n",
    "\n",
    "# Only keep features of the new compounds that also exist in df_all_3\n",
    "for item in df_Mordred_extra_no_name:\n",
    "    if item not in features:\n",
    "        df_Mordred_extra_no_name = df_Mordred_extra_no_name.drop(item, axis=1)\n",
    "\n",
    "# Replace infinity in the feature values by nan values\n",
    "df_Mordred_extra_no_name.replace([np.inf, -np.inf], np.nan, inplace=True)     \n",
    "\n",
    "# Fill nan values of the test matrix with median of df_all_3 columns\n",
    "for i in range(8):\n",
    "    for item in features:\n",
    "        if np.isnan(df_Mordred_extra_no_name.at[i, item]) == True:\n",
    "            df_Mordred_extra_no_name.at[i, item] = median_values_dict[item]\n",
    "            \n",
    "df_Mordred_extra_no_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on the new compound dataset\n",
    "\n",
    "# Load in the standardscalar package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load in the standardization used in standardizing the training set\n",
    "sc = pickle.load(open(folder_dir + \"/ML_CSVs/scaler.pkl\", 'rb'))\n",
    "\n",
    "# Standardize the new compound dataset using the standardization parameters derived from the training set\n",
    "X_extra_test = df_Mordred_extra_no_name.values\n",
    "X_extra_test = sc.transform(X_extra_test)\n",
    "\n",
    "# Use the MLP model to predict the chance of RNA binding over protein binding\n",
    "prediction = [item[0] for item in reconstructed_model.predict(X_extra_test).tolist()]\n",
    "\n",
    "# Print compound name followed by the probability predicted by model\n",
    "for i in range(len(prediction)):\n",
    "    print(Mordred_extra_names[i])\n",
    "    print(round(prediction[i]*100, 1))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
